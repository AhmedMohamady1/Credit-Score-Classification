{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1da9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atef1\\AppData\\Local\\Temp\\ipykernel_10392\\3960688682.py:15: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('train.csv')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Target'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\atef1\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\atef1\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\atef1\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Target'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Load data\u001b[39;00m\n\u001b[0;32m     15\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m y \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTarget\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\atef1\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:5543\u001b[0m, in \u001b[0;36mDataFrame.pop\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   5502\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpop\u001b[39m(\u001b[38;5;28mself\u001b[39m, item: Hashable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[0;32m   5503\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5504\u001b[0m \u001b[38;5;124;03m    Return item and drop from frame. Raise KeyError if not found.\u001b[39;00m\n\u001b[0;32m   5505\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5541\u001b[0m \u001b[38;5;124;03m    3  monkey        NaN\u001b[39;00m\n\u001b[0;32m   5542\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5543\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mpop(item\u001b[38;5;241m=\u001b[39mitem)\n",
      "File \u001b[1;32mc:\\Users\\atef1\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:853\u001b[0m, in \u001b[0;36mNDFrame.pop\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpop\u001b[39m(\u001b[38;5;28mself\u001b[39m, item: Hashable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m Any:\n\u001b[1;32m--> 853\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m[item]\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m[item]\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\atef1\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\atef1\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Target'"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports & Data Load\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import mode\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('data/train.csv')\n",
    "y = df.pop('Credit_Score')    # ← adjust to your actual target column name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1142c71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1ae2822",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoanModeImputer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Fill NaNs & cap outliers to the group MODE, without dropping any rows.\"\"\"\n",
    "    def __init__(self, group_col, value_col, na_placeholder=\"__MISSING__\"):\n",
    "        self.group_col = group_col\n",
    "        self.value_col = value_col\n",
    "        self.na_placeholder = na_placeholder\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        # 1) fill missing loan-type so groupby won't drop rows\n",
    "        X[self.group_col] = X[self.group_col].fillna(self.na_placeholder)\n",
    "\n",
    "        def clean_grp(g):\n",
    "            s = g[self.value_col]\n",
    "            # compute group mode\n",
    "            try:\n",
    "                m = mode(s.dropna())[0][0]\n",
    "            except:\n",
    "                m = np.nan\n",
    "            # IQR bounds\n",
    "            q1, q3 = s.quantile([.25, .75])\n",
    "            iqr = q3 - q1\n",
    "            low, high = q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
    "            # replace NaNs & cap outliers to mode\n",
    "            s = s.fillna(m).apply(lambda x: m if x < low or x > high else x)\n",
    "            g[self.value_col] = s.fillna(m)\n",
    "            return g\n",
    "\n",
    "        # group_keys=False preserves original ordering and length\n",
    "        return X.groupby(self.group_col, group_keys=False).apply(clean_grp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5af2d247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Full-DF → ColumnSelector+Scaler Preprocessor\n",
    "numeric_strip_cols = [\n",
    "    \"Age\", \"Annual_Income\", \"Monthly_Inhand_Salary\", \"Num_Bank_Accounts\",\n",
    "    \"Num_Credit_Card\", \"Interest_Rate\", \"Num_of_Loan\", \"Delay_from_due_date\",\n",
    "    \"Num_of_Delayed_Payment\", \"Changed_Credit_Limit\", \"Num_Credit_Inquiries\",\n",
    "    \"Outstanding_Debt\", \"Total_EMI_per_month\", \"Amount_invested_monthly\",\n",
    "    \"Monthly_Balance\"\n",
    "]\n",
    "static_cols = [\"Age\", \"Occupation\", \"Annual_Income\", \"Monthly_Inhand_Salary\",\n",
    "               \"Num_Bank_Accounts\", \"Num_Credit_Card\", \"Interest_Rate\"]\n",
    "loan_col, group_col = \"Num_of_Loan\", \"Type_of_Loan\"\n",
    "cat_clean_cols = ['Credit_Mix','Payment_Behaviour','Occupation']\n",
    "mode_impute_cols = cat_clean_cols + ['Payment_of_Min_Amount','Month','Credit_Score']\n",
    "label_encode_cols = mode_impute_cols + ['Credit_History_Age_months']\n",
    "\n",
    "# Stage 1: run all custom transformers to completion on the full DF\n",
    "full_df_pipeline = Pipeline([\n",
    "    ('strip', StripAndNumeric(numeric_strip_cols)),\n",
    "    ('static', StaticFieldImputer('Customer_ID', static_cols)),\n",
    "    ('loan_mode', LoanModeImputer(group_col, loan_col)),\n",
    "    ('cred_age', CreditHistoryConverter('Credit_History_Age')),\n",
    "    ('cat_clean', CategoryCleaner(cat_clean_cols)),\n",
    "    ('mode_imp', LocalModeImputer(mode_impute_cols)),\n",
    "    ('lbl_enc', LabelEncoderImputer(label_encode_cols)),\n",
    "])\n",
    "\n",
    "# Stage 2: select & scale\n",
    "selector_and_scaler = ColumnTransformer([\n",
    "    ('num_scale',\n",
    "     Pipeline([('impute', SimpleImputer(strategy='median')),\n",
    "               ('std', StandardScaler())]),\n",
    "     numeric_strip_cols + ['Credit_History_Age_months']),\n",
    "    ('cat_scale',\n",
    "     Pipeline([('impute0', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "               ('minmax', MinMaxScaler())]),\n",
    "     mode_impute_cols),\n",
    "], remainder='drop')\n",
    "\n",
    "preprocessor = Pipeline([\n",
    "    ('full_df', full_df_pipeline),\n",
    "    ('sel_scale', selector_and_scaler)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3c7ec2",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4990a784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC, SVR, LinearSVC, OneClassSVM\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import os\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d7755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"C\": 1.0,\n",
    "    \"kernel\": 'rbf',\n",
    "    \"gamma\": 'scale',\n",
    "    \"degree\": 3,\n",
    "    \"coef0\": 0.0,\n",
    "    \"probability\": True,\n",
    "    \"shrinking\": True,\n",
    "    \"tol\": 0.001,\n",
    "    \"max_iter\": -1,\n",
    "    \"class_weight\": None,\n",
    "    \"decision_function_shape\": 'ovr',\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "svc = SVC(**params)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cecf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_dict = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Save classification report text\n",
    "with open(\"outputs/classification_report.txt\", \"w\") as f:\n",
    "    f.write(str(report_dict))\n",
    "\n",
    "# Create and save confusion matrix plot\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "conf_matrix_path = \"outputs/confusion_matrix.png\"\n",
    "plt.savefig(conf_matrix_path)\n",
    "plt.close()\n",
    "\n",
    "classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e99aa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"SVM_Classifier\")\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000/\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"SVM_run\"):\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_metrics({\n",
    "        'accuracy': report_dict['accuracy'],\n",
    "        'weighted_avg_precision': report_dict['weighted avg']['precision'],\n",
    "        'weighted_avg_recall': report_dict['weighted avg']['recall'],\n",
    "        'weighted_avg_f1': report_dict['weighted avg']['f1-score']\n",
    "    })\n",
    "    mlflow.sklearn.log_model(svc, \"Supprt Vector Classifier\")\n",
    "    mlflow.log_artifact(\"outputs/classification_report.txt\")\n",
    "    mlflow.log_artifact(conf_matrix_path)\n",
    "    mlflow.log_text(\"Support Vector Classifier primary trial.\", artifact_file=\"outputs/evaluation_notes.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
