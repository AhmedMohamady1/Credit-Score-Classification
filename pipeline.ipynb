{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca1da9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Core imports & column‐lists\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import mode\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1142c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/82/38y74ydn1w15pytl9kly5mz40000gn/T/ipykernel_31566/3829924280.py:2: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('data/train.csv')\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('data/train.csv')\n",
    "y = df.pop('Credit_Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e7e60b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your column‐lists\n",
    "numeric_strip_cols = [\n",
    "    \"Age\", \"Annual_Income\", \"Monthly_Inhand_Salary\", \"Num_Bank_Accounts\",\n",
    "    \"Num_Credit_Card\", \"Interest_Rate\", \"Num_of_Loan\", \"Delay_from_due_date\",\n",
    "    \"Num_of_Delayed_Payment\", \"Changed_Credit_Limit\", \"Num_Credit_Inquiries\",\n",
    "    \"Outstanding_Debt\", \"Total_EMI_per_month\", \"Amount_invested_monthly\",\n",
    "    \"Monthly_Balance\"\n",
    "]\n",
    "static_cols = [\"Age\", \"Occupation\", \"Annual_Income\", \"Monthly_Inhand_Salary\",\n",
    "               \"Num_Bank_Accounts\", \"Num_Credit_Card\", \"Interest_Rate\"]\n",
    "group_col = \"Type_of_Loan\"\n",
    "loan_col  = \"Num_of_Loan\"\n",
    "cat_clean_cols    = ['Credit_Mix','Payment_Behaviour','Occupation']\n",
    "mode_impute_cols  = cat_clean_cols + ['Payment_of_Min_Amount','Month']\n",
    "label_encode_cols = mode_impute_cols + ['Credit_History_Age_months']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1ae2822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Define ALL custom Transformers\n",
    "\n",
    "class StripAndNumeric(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols): self.cols = cols\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for c in self.cols:\n",
    "            X[c] = (\n",
    "                X[c].astype(str)\n",
    "                     .str.replace(r'[-_]', '', regex=True)\n",
    "                     .pipe(pd.to_numeric, errors='coerce')\n",
    "            )\n",
    "        return X\n",
    "\n",
    "class StaticFieldImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, id_col, cols):\n",
    "        self.id_col, self.cols = id_col, cols\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for c in self.cols:\n",
    "            X[c] = X.groupby(self.id_col)[c]\\\n",
    "                    .transform(lambda g: g.ffill().bfill().iloc[0])\n",
    "        return X\n",
    "\n",
    "# Cell 2: Define ALL custom Transformers\n",
    "\n",
    "class StripAndNumeric(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols): self.cols = cols\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for c in self.cols:\n",
    "            X[c] = (\n",
    "                X[c].astype(str)\n",
    "                     .str.replace(r'[-_]', '', regex=True)\n",
    "                     .pipe(pd.to_numeric, errors='coerce')\n",
    "            )\n",
    "        return X\n",
    "\n",
    "class StaticFieldImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, id_col, cols):\n",
    "        self.id_col, self.cols = id_col, cols\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for c in self.cols:\n",
    "            X[c] = X.groupby(self.id_col)[c]\\\n",
    "                    .transform(lambda g: g.ffill().bfill().iloc[0])\n",
    "        return X\n",
    "\n",
    "class LoanModeImputer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Fill NaNs & cap outliers to the group MODE, without dropping any rows.\"\"\"\n",
    "    def __init__(self, group_col, value_col, na_placeholder=\"__MISSING__\"):\n",
    "        self.group_col = group_col\n",
    "        self.value_col = value_col\n",
    "        self.na_placeholder = na_placeholder\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        # ensure every row is in a group\n",
    "        # ensure every row is in a group\n",
    "        X[self.group_col] = X[self.group_col].fillna(self.na_placeholder)\n",
    "\n",
    "        def clean_grp(g):\n",
    "            s = g[self.value_col]\n",
    "            try:\n",
    "                m = mode(s.dropna())[0][0]\n",
    "            except:\n",
    "                m = np.nan\n",
    "            q1, q3 = s.quantile([.25, .75])\n",
    "            iqr = q3 - q1\n",
    "            low, high = q1 - 1.5*iqr, q3 + 1.5*iqr\n",
    "            # fill & cap\n",
    "            low, high = q1 - 1.5*iqr, q3 + 1.5*iqr\n",
    "            # fill & cap\n",
    "            s = s.fillna(m).apply(lambda x: m if x < low or x > high else x)\n",
    "            g[self.value_col] = s.fillna(m)\n",
    "            return g\n",
    "\n",
    "        return X.groupby(self.group_col, group_keys=False).apply(clean_grp)\n",
    "\n",
    "class CategoryCleaner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols): self.cols = cols\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for c in self.cols:\n",
    "            X[c] = (\n",
    "                X[c].astype(str)\n",
    "                    .str.replace(r'[^A-Za-z\\s]', '', regex=True)\n",
    "                    .str.strip()\n",
    "                    .str.replace(r'\\s+', '_', regex=True)\n",
    "                    .str.lower()\n",
    "            )\n",
    "        return X\n",
    "\n",
    "class LocalModeImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols, window=5):\n",
    "        self.cols, self.window = cols, window\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for c in self.cols:\n",
    "            vals = X[c].replace(r'^\\s*$', np.nan, regex=True)\n",
    "            counts = vals.value_counts(dropna=True)\n",
    "            rare = set(counts[counts==1].index)\n",
    "            arr = vals.copy()\n",
    "            n = len(arr)\n",
    "            for i in range(n):\n",
    "                v = arr.iat[i]\n",
    "                if pd.isna(v) or v in rare:\n",
    "                    lo, hi = max(0, i-self.window), min(n, i+self.window+1)\n",
    "                    w = arr.iloc[lo:hi].dropna()\n",
    "                    if not w.empty:\n",
    "                        arr.iat[i] = w.mode().iat[0]\n",
    "            X[c] = arr\n",
    "        return X\n",
    "\n",
    "class CreditHistoryConverter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, col): self.col = col\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        def to_m(val):\n",
    "            m = re.match(r'(\\d+)\\s+Years?\\s+and\\s+(\\d+)\\s+Months?', str(val))\n",
    "            return int(m[1])*12 + int(m[2]) if m else np.nan\n",
    "        X[self.col + '_months'] = X[self.col].map(to_m)\n",
    "        return X\n",
    "\n",
    "class LabelEncoderImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "        self.encs = {}\n",
    "    def fit(self, X, y=None):\n",
    "        for c in self.cols:\n",
    "            le = LabelEncoder()\n",
    "            nonnull = X[c].dropna().astype(str)\n",
    "            if not nonnull.empty:\n",
    "                le.fit(nonnull)\n",
    "                self.encs[c] = le\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for c, le in self.encs.items():\n",
    "            mask = X[c].notna()\n",
    "            X.loc[mask, c] = le.transform(X.loc[mask, c].astype(str))\n",
    "        return X\n"
    "        return X.groupby(self.group_col, group_keys=False).apply(clean_grp)\n",
    "\n",
    "class CategoryCleaner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols): self.cols = cols\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for c in self.cols:\n",
    "            X[c] = (\n",
    "                X[c].astype(str)\n",
    "                    .str.replace(r'[^A-Za-z\\s]', '', regex=True)\n",
    "                    .str.strip()\n",
    "                    .str.replace(r'\\s+', '_', regex=True)\n",
    "                    .str.lower()\n",
    "            )\n",
    "        return X\n",
    "\n",
    "class LocalModeImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols, window=5):\n",
    "        self.cols, self.window = cols, window\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for c in self.cols:\n",
    "            vals = X[c].replace(r'^\\s*$', np.nan, regex=True)\n",
    "            counts = vals.value_counts(dropna=True)\n",
    "            rare = set(counts[counts==1].index)\n",
    "            arr = vals.copy()\n",
    "            n = len(arr)\n",
    "            for i in range(n):\n",
    "                v = arr.iat[i]\n",
    "                if pd.isna(v) or v in rare:\n",
    "                    lo, hi = max(0, i-self.window), min(n, i+self.window+1)\n",
    "                    w = arr.iloc[lo:hi].dropna()\n",
    "                    if not w.empty:\n",
    "                        arr.iat[i] = w.mode().iat[0]\n",
    "            X[c] = arr\n",
    "        return X\n",
    "\n",
    "class CreditHistoryConverter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, col): self.col = col\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        def to_m(val):\n",
    "            m = re.match(r'(\\d+)\\s+Years?\\s+and\\s+(\\d+)\\s+Months?', str(val))\n",
    "            return int(m[1])*12 + int(m[2]) if m else np.nan\n",
    "        X[self.col + '_months'] = X[self.col].map(to_m)\n",
    "        return X\n",
    "\n",
    "class LabelEncoderImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "        self.encs = {}\n",
    "    def fit(self, X, y=None):\n",
    "        for c in self.cols:\n",
    "            le = LabelEncoder()\n",
    "            nonnull = X[c].dropna().astype(str)\n",
    "            if not nonnull.empty:\n",
    "                le.fit(nonnull)\n",
    "                self.encs[c] = le\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for c, le in self.encs.items():\n",
    "            mask = X[c].notna()\n",
    "            X.loc[mask, c] = le.transform(X.loc[mask, c].astype(str))\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5af2d247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features → ['Age', 'Annual_Income', 'Monthly_Inhand_Salary', 'Num_Bank_Accounts', 'Num_Credit_Card', 'Interest_Rate', 'Num_of_Loan', 'Delay_from_due_date', 'Num_of_Delayed_Payment', 'Changed_Credit_Limit', 'Num_Credit_Inquiries', 'Outstanding_Debt', 'Total_EMI_per_month', 'Amount_invested_monthly', 'Monthly_Balance']\n",
      "Categorical features → ['Credit_Mix', 'Payment_Behaviour', 'Occupation', 'Payment_of_Min_Amount', 'Month']\n"
     ]
    }
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features → ['Age', 'Annual_Income', 'Monthly_Inhand_Salary', 'Num_Bank_Accounts', 'Num_Credit_Card', 'Interest_Rate', 'Num_of_Loan', 'Delay_from_due_date', 'Num_of_Delayed_Payment', 'Changed_Credit_Limit', 'Num_Credit_Inquiries', 'Outstanding_Debt', 'Total_EMI_per_month', 'Amount_invested_monthly', 'Monthly_Balance']\n",
      "Categorical features → ['Credit_Mix', 'Payment_Behaviour', 'Occupation', 'Payment_of_Min_Amount', 'Month']\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Build `preprocessor` cleanly, excluding Credit_Score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# 1) Make sure our intended lists do NOT contain the target:\n",
    "mode_impute_cols  = ['Credit_Mix','Payment_Behaviour','Occupation',\n",
    "                     'Payment_of_Min_Amount','Month']   # no Credit_Score here!\n",
    "# Cell 3: Build `preprocessor` cleanly, excluding Credit_Score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# 1) Make sure our intended lists do NOT contain the target:\n",
    "mode_impute_cols  = ['Credit_Mix','Payment_Behaviour','Occupation',\n",
    "                     'Payment_of_Min_Amount','Month']   # no Credit_Score here!\n",
    "label_encode_cols = mode_impute_cols + ['Credit_History_Age_months']\n",
    "\n",
    "# 2) Compute only-they-exist lists from df.columns:\n",
    "num_cols = [c for c in numeric_strip_cols + ['Credit_History_Age_months']\n",
    "            if c in df.columns]\n",
    "cat_cols = [c for c in mode_impute_cols\n",
    "            if c in df.columns]\n",
    "\n",
    "print(\"Numeric features →\", num_cols)\n",
    "print(\"Categorical features →\", cat_cols)\n",
    "\n",
    "# 3) Two‐stage pipeline:\n",
    "\n",
    "# Stage A: apply all custom transformers (creates the new '_months' col and label-encodes cats)\n",
    "# 2) Compute only-they-exist lists from df.columns:\n",
    "num_cols = [c for c in numeric_strip_cols + ['Credit_History_Age_months']\n",
    "            if c in df.columns]\n",
    "cat_cols = [c for c in mode_impute_cols\n",
    "            if c in df.columns]\n",
    "\n",
    "print(\"Numeric features →\", num_cols)\n",
    "print(\"Categorical features →\", cat_cols)\n",
    "\n",
    "# 3) Two‐stage pipeline:\n",
    "\n",
    "# Stage A: apply all custom transformers (creates the new '_months' col and label-encodes cats)\n",
    "full_df_pipeline = Pipeline([\n",
    "    ('strip',     StripAndNumeric(numeric_strip_cols)),\n",
    "    ('static',    StaticFieldImputer('Customer_ID', static_cols)),\n",
    "    ('strip',     StripAndNumeric(numeric_strip_cols)),\n",
    "    ('static',    StaticFieldImputer('Customer_ID', static_cols)),\n",
    "    ('loan_mode', LoanModeImputer(group_col, loan_col)),\n",
    "    ('cred_age',  CreditHistoryConverter('Credit_History_Age')),\n",
    "    ('cred_age',  CreditHistoryConverter('Credit_History_Age')),\n",
    "    ('cat_clean', CategoryCleaner(cat_clean_cols)),\n",
    "    ('mode_imp',  LocalModeImputer(mode_impute_cols)),\n",
    "    ('lbl_enc',   LabelEncoderImputer(label_encode_cols)),\n",
    "    ('mode_imp',  LocalModeImputer(mode_impute_cols)),\n",
    "    ('lbl_enc',   LabelEncoderImputer(label_encode_cols)),\n",
    "])\n",
    "\n",
    "# Stage B: select & impute-with-mode + scale\n",
    "# Stage B: select & impute-with-mode + scale\n",
    "selector_and_scaler = ColumnTransformer([\n",
    "    ('num', Pipeline([\n",
    "        ('imp_mode', SimpleImputer(strategy='most_frequent')),\n",
    "        ('std',      StandardScaler())\n",
    "    ]), num_cols),\n",
    "    ('cat', Pipeline([\n",
    "        ('imp_mode', SimpleImputer(strategy='most_frequent')),\n",
    "        ('mm',       MinMaxScaler())\n",
    "    ]), cat_cols),\n",
    "    ('num', Pipeline([\n",
    "        ('imp_mode', SimpleImputer(strategy='most_frequent')),\n",
    "        ('std',      StandardScaler())\n",
    "    ]), num_cols),\n",
    "    ('cat', Pipeline([\n",
    "        ('imp_mode', SimpleImputer(strategy='most_frequent')),\n",
    "        ('mm',       MinMaxScaler())\n",
    "    ]), cat_cols),\n",
    "], remainder='drop')\n",
    "\n",
    "# Final preprocessor\n",
    "# Final preprocessor\n",
    "preprocessor = Pipeline([\n",
    "    ('full_df', full_df_pipeline),\n",
    "    ('select',  selector_and_scaler),\n",
    "    ('select',  selector_and_scaler),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cca02ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/82/38y74ydn1w15pytl9kly5mz40000gn/T/ipykernel_31566/941475875.py:56: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return X.groupby(self.group_col, group_keys=False).apply(clean_grp)\n",
      "/var/folders/82/38y74ydn1w15pytl9kly5mz40000gn/T/ipykernel_31566/941475875.py:56: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return X.groupby(self.group_col, group_keys=False).apply(clean_grp)\n",
      "/Users/ahmedmohamady/University/Data Computation Project/Credit-Score-Classification/venv/lib/python3.13/site-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=42)\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3c7ec2",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4990a784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Model Pipeline, Train/Test & Eval\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = Pipeline([\n",
    "    ('preproc', preprocessor),\n",
    "    ('svm',     SVC(kernel='rbf', C=1.0, random_state=42))\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d7755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"C\": 2.0,\n",
    "    \"kernel\": 'rbf',\n",
    "    \"gamma\": 'scale',\n",
    "    \"degree\": 3,\n",
    "    \"coef0\": 0.0,\n",
    "    \"probability\": True,\n",
    "    \"shrinking\": True,\n",
    "    \"tol\": 0.001,\n",
    "    \"max_iter\": -1,\n",
    "    \"class_weight\": None,\n",
    "    \"decision_function_shape\": 'ovr',\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "svc = SVC(**params)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cecf45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n        Good       0.51      0.58      0.54      3527\\n        Poor       0.69      0.54      0.61      5874\\n    Standard       0.68      0.73      0.70     10599\\n\\n    accuracy                           0.65     20000\\n   macro avg       0.63      0.62      0.62     20000\\nweighted avg       0.65      0.65      0.65     20000\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_dict = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Save classification report text\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "with open(\"outputs/classification_report.txt\", \"w\") as f:\n",
    "    f.write(str(report_dict))\n",
    "\n",
    "# Create and save confusion matrix plot\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "conf_matrix_path = \"outputs/confusion_matrix.png\"\n",
    "plt.savefig(conf_matrix_path)\n",
    "plt.close()\n",
    "\n",
    "classification_report(y_test, y_pred, output_dict=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e99aa00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/05/03 19:54:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(f\"file://{os.getcwd()}/mlruns\")  # ✅ this is safe\n",
    "\n",
    "mlflow.set_experiment(\"SVM_Classifier\")\n",
    "\n",
    "\n",
    "with mlflow.start_run(run_name=\"SVM_run\"):\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_metrics({\n",
    "        'accuracy': report_dict['accuracy'],\n",
    "        'weighted_avg_precision': report_dict['weighted avg']['precision'],\n",
    "        'weighted_avg_recall': report_dict['weighted avg']['recall'],\n",
    "        'weighted_avg_f1': report_dict['weighted avg']['f1-score']\n",
    "    })\n",
    "    mlflow.log_input(\"train_data\", X_train)\n",
    "    mlflow.sklearn.log_model(svc, \"Supprt Vector Classifier\")\n",
    "    mlflow.log_artifact(\"outputs/classification_report.txt\")\n",
    "    mlflow.log_artifact(conf_matrix_path)\n",
    "    mlflow.log_text(\"Support Vector Classifier primary trial.\", artifact_file=\"outputs/evaluation_notes.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c8f1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking URI is: file:///mlruns\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Model Pipeline, Train/Test & Eval\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = Pipeline([\n",
    "    ('preproc', preprocessor),\n",
    "    ('svm',     SVC(kernel='rbf', C=1.0, random_state=42))\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "# Cell 5: Save the model\n",
    "import joblib\n",
    "import os\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "joblib.dump(model, \"outputs/svm_model.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
